{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA_VSM_Dizionario.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build Sentiment Dictionaries from VSMs\n",
        "\n",
        "This script allows you to create your own Sentiment Dictionary using Vector Space Models"
      ],
      "metadata": {
        "id": "RFe3xDyK6px1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparation\n",
        "\n",
        "Download the model.  \n",
        "You can select any model from here: https://fasttext.cc/docs/en/crawl-vectors.html"
      ],
      "metadata": {
        "id": "9wv7zBLw64I_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfbBGs-35NI5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gensim\n",
        "import urllib.request\n",
        "import os.path\n",
        "import pandas\n",
        "import numpy as np\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we download the model\n",
        "# remember to change URL and filename according to the model you want \n",
        "# here we do a test with the Italian model, named \"cc.it.300.vec.gz\"\n",
        "\n",
        "!wget \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz\"\n",
        "!gunzip cc.it.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s4E6zBQ5rb-",
        "outputId": "eeb645e5-da1b-4ef5-c29a-b0759d1f98e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 10:02:10--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1272825284 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.it.300.vec.gz’\n",
            "\n",
            "cc.it.300.vec.gz    100%[===================>]   1.18G  40.8MB/s    in 32s     \n",
            "\n",
            "2022-06-07 10:02:42 (38.5 MB/s) - ‘cc.it.300.vec.gz’ saved [1272825284/1272825284]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to change the filename according to the model you downloaded \n",
        "# here we do a test with the Italian model, named \"cc.it.300.vec\" (note that \".gz\" is not in the name anymore, as we unzipped the file)\n",
        "\n",
        "filename = 'cc.it.300.vec'\n",
        "\n",
        "my_model = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=False)"
      ],
      "metadata": {
        "id": "nfFntLbU5Srw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare SA lexicon\n",
        "\n",
        "Here you need to define the \"seed words\" for your lexicon.  \n",
        "Here we test it with two dimensions, \"happy\" and \"sad\" (but you can use many different dimensions). "
      ],
      "metadata": {
        "id": "mvZBmncz8dL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happy_labels = ['felice', 'contento'] # note that you can add how many words you like!\n",
        "sad_labels = ['triste', 'dispiaciuto'] # note that you can add how many words you like!\n",
        "# you can add more labels for more categories, if you like...\n",
        "\n",
        "all_words = list(my_model.vocab.keys())"
      ],
      "metadata": {
        "id": "n6Uyw3Dx80Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happy_ordered_words = my_model.most_similar(positive = happy_labels, topn = len(all_words))\n",
        "sad_ordered_words = my_model.most_similar(positive = sad_labels, topn = len(all_words))\n",
        "# you can add more categories, if you like..."
      ],
      "metadata": {
        "id": "S0hEW4UX9N06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# happy\n",
        "happy_words = []\n",
        "happy_value = []\n",
        "\n",
        "for my_tuple in happy_ordered_words:\n",
        "  happy_words.append(my_tuple[0])\n",
        "  happy_value.append(my_tuple[1])\n",
        "\n",
        "# sad\n",
        "sad_words = []\n",
        "sad_value = []\n",
        "\n",
        "for my_tuple in sad_ordered_words:\n",
        "  sad_words.append(my_tuple[0])\n",
        "  sad_value.append(my_tuple[1])\n",
        "\n",
        "# you can add more categories, if you like..."
      ],
      "metadata": {
        "id": "iYLHL44X9jO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# happy\n",
        "happy_value = np.array(happy_value)\n",
        "happy_value = stats.zscore(happy_value)\n",
        "\n",
        "happy_df = pandas.DataFrame(list(zip(happy_words, happy_value)), \n",
        "               columns =['word', 'happy'])\n",
        "\n",
        "happy_df = happy_df.sort_values('word', ascending=True)\n",
        "\n",
        "\n",
        "# sad\n",
        "sad_value = np.array(sad_value)\n",
        "sad_value = stats.zscore(sad_value)\n",
        "\n",
        "sad_df = pandas.DataFrame(list(zip(sad_words, sad_value)), \n",
        "               columns =['word', 'sad'])\n",
        "\n",
        "sad_df = sad_df.sort_values('word', ascending=True)\n",
        "\n",
        "# you can add more categories, if you like..."
      ],
      "metadata": {
        "id": "F-Tm3117-F5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save all to unique dataframe\n",
        "sa_df = happy_df.merge(sad_df, how = 'inner', on = ['word'])\n",
        "sa_df [\"valence\"] = sa_df[\"happy\"] - sa_df[\"sad\"] \n",
        "# if you add more categories, you should re-write the command above like that:\n",
        "# sa_df = happy_df.merge(sad_df, fear_df, surprise_df, ..., how = 'inner', on = ['word'])\n",
        "\n",
        "sa_df.to_csv('my_SA_dictionary.csv', index=False)"
      ],
      "metadata": {
        "id": "fJ5eVBSK-tmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}